# 视觉SLAM中的研究点总结


本文为个人学习、阅读文献以及工程项目实践中对于SLAM算法目前存在的问题和一些可行的论文创新点的总结。对于其中的内容有不当之处欢迎在Issues中进行讨论。

> **目录**
> 1. 概述
> 2. 针对视觉SLAM系统各模块的研究
>     1. 信息采集——新式传感器/多传感器
>     2. 信息提取——特征提取
>     3. 信息关联——特征匹配
>     4. 信息处理（位姿）—— 基于关键帧结构的后端优化
>     5. 信息处理（地图）—— 地图构建
>     6. 端到端的多任务处理
> 3. 视觉SLAM相关的其他任务
>     1. 先构建视觉特征地图后定位的视觉定位算法

## 概述

视觉SLAM算法目前遇到的困境在于理论的成熟度与实际的落地应用情况的不匹配。在经典的ORB-SLAM2,ORB-SLAM3等解决方案面前似乎SLAM是一个已经被解决的问题。但是在众多的移动机器人以及各种应用如VR，AR中却迟迟没有落地，这是由于其在鲁棒性和精度等方面依旧纯在明显的短板。另一方面，近年来越来越多的研究者加入这一领域，却发现前辈们的工作理论复杂度高、工程实现难、算法改进更是无从谈起，因此跟随书籍、课程学习一段相关基础知识便陷入无从下手的困境。因此，本文抛砖引玉，提出一些SLAM中可以去深入挖掘的一些点，给研究者提供一个思路。本文会随着个人的学习、实践中的成长，逐步修改添加其中的一些问题。也欢迎各位加入共同完善这一工作。

## 信息采集——新式传感器/多传感器

目标：**在各种极端环境下采集到尽量多的数据**
关键字：**互补**

信息采集上需要考虑目前常用的视觉传感器的不足之处，采用可以补充这一部分信息的传感器并融合或者单独使用在特定环境下对现有算法进行补充。

如：
1. 视觉 + IMU
    1. 单目视觉具有尺度不确定性，添加IMU中的加速度计补充尺度信息
    2. 低级视觉特征对视角不变性差，因此添加IMU中的陀螺仪信息,提高特征关联的效率
2. RGB相机 + 红外相机
    1. RGB 相机对光照变化敏感，在黑夜环境中无法使用，因此添加红外相机进行互补
3. 鱼眼相机/360°相机
    1. 传统相机视角小，快速运动下若有几帧数据没有及时处理视角转到另一个角度后必然导致跟踪失败。而360°相机或者尽量大广角的相机则可以更好的避免这一点。

### 单一传感器

#### 鱼眼镜头
鱼眼镜头的优势在于单一传感器即可获取超大视野，一般可以超过180°。但是缺点也很明显，即畸变严重、标定复杂。

#### 360相机
基于目前商用的360相机做SLAM算法研究。

#### 相机参数的主动控制
传感器本身的参数设置对于图像质量的影响也是至关重要。


#### 事件相机
事件相机是一个新型传感器，

### 多传感器融合

#### VIO （视觉惯性里程计）

#### 多相机的全景相机

#### RGB相机 + 红外相机


## 信息提取——特征提取

## 信息关联——特征匹配

## 信息处理（位姿）—— 基于关键帧结构的后端优化

## 信息处理（地图）—— 地图构建

## 端到端的多任务处理

